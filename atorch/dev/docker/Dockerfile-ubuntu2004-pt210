##############################################################################
# base image: nvidia/cuda:11.8.0-cudnn8-devel-ubuntu20.04
# default versions
# PYTHON_VERSION=3.8
# TORCH_VERSION=2.1.0
# CUDA_VERSON=11.8
##############################################################################
FROM easydl/pytorch_gpu_base:2.1.0-cuda12.1-cudnn8-devel as base

ARG PYTHON_VERSION=3.8

USER root
WORKDIR /root

ENV BASH_ENV /root/.bashrc
ENV SHELL /bin/bash

# Already exist in base
# COPY dev/docker/pip.conf ~/.pip/pip.conf

# RUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list
# RUN sed -i s@/security.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list
# RUN apt-get clean

##############################################################################
# conda and other utils
##############################################################################
FROM base as util-base
ARG PYTHON_VERSION=3.8

RUN cd ~/ && \
    apt-get update && apt-get install -y wget git vim
    # wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh --no-check-certificate -O miniconda-install.sh && \
    # chmod +x miniconda-install.sh

##############################################################################
# rdma, cuda compat
##############################################################################
FROM util-base as torch-base

COPY dev/docker/handle_driver_compat.sh ./

RUN echo "/usr/local/cuda/lib" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "/usr/local/cuda/lib64" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "/usr/lib64" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "ldconfig > /dev/null 2>&1 " >> /etc/bashrc && \
    apt-get install -y build-essential libnl-3-dev libgl1-mesa-dev git && \
    apt-get clean all && \
    cat handle_driver_compat.sh >> /etc/bashrc && \
    rm -rf handle_driver_compat.sh

# ibutils
RUN apt-get install -y ibverbs-utils rdma-core && \
    apt-get install -y pciutils net-tools opensm
##############################################################################
# apex, flash-attention, fastmoe, transformer_engine
# Apex: 623315a5d1b47b0addf00bbfd15017e5605750bc
# aistudio
##############################################################################
FROM torch-base as atorch-fa-base
ENV USE_NCCL=1
ARG TORCH_CUDA_ARCH_LIST="6.0 7.0 7.5 8.0 8.6 8.9 9.0+PTX"
# RUN yum install libnccl-2.16.2-1+cuda11.0 libnccl-devel-2.16.2-1+cuda11.0 -y && \
RUN pip install https://dlrover.oss-cn-beijing.aliyuncs.com/atorch/libs/fastmoe.tar.gz
RUN pip install dm-tree setuptools packaging && \
    wget -O apex.zip https://dlrover.oss-cn-beijing.aliyuncs.com/atorch/libs/apex-master.zip && \
    apt-get install -y unzip && \
    unzip apex.zip -d ./ && \
    cd ./apex-master && \
    MAKEFLAGS="-j$(nproc)" MAX_JOBS=16 \
    pip install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./ && \
    cd .. && rm -rf apex*

RUN pip install https://dlrover.oss-cn-beijing.aliyuncs.com/atorch/libs/flash_attn-2.3.6%2Bpack.glm.mask-cp38-cp38-linux_x86_64.whl
RUN wget -O catapult.tar.gz https://dlrover.oss-cn-beijing.aliyuncs.com/atorch/libs/catapult.tar.gz && \
    mkdir -p /home/admin/profile/ && \
    tar -zxf catapult.tar.gz -C /home/admin/profile/ && \
    rm -f catapult.tar.gz

# tar file is from "git clone --branch stable --recursive https://github.com/NVIDIA/TransformerEngine.git" with version 1.2.0
RUN wget -O TransformerEngine.tar.gz https://dlrover.oss-cn-beijing.aliyuncs.com/atorch/libs/TransformerEngine.tar.gz && \
    tar xfz TransformerEngine.tar.gz && \
    cd TransformerEngine && \
    CUDACXX=/usr/local/cuda/bin/nvcc NVTE_FRAMEWORK=pytorch python setup.py bdist_wheel && \
    pip install --default-timeout=600 dist/transformer_engine*.whl && \
    cd .. && rm -rf TransformerEngine

##############################################################################
# atorch install
##############################################################################
FROM atorch-fa-base as atorch-base
ENV TORCH_CUDA_ARCH_LIST="6.0 7.0 7.5 8.0 8.6 9.0+PTX"
COPY atorch/requirements.txt ./
RUN pip install --default-timeout=600 grpcio==1.62.1 grpcio-tools==1.58.0 protobuf==4.25.3 tensorboard==2.14.0 grouped_gemm==0.1.4 megablocks===0.5.1 -i https://artifacts.antgroup-inc.cn/simple/
RUN grep -v -e dlrover -e tensorboard -e grpcio -e grpcio-tools -e protobuf requirements.txt > tmp_requirements.txt && \
    pip install --default-timeout=600 -r tmp_requirements.txt -i https://artifacts.antgroup-inc.cn/simple/ && \
    rm -f ./tmp_requirements.txt && \
    rm -f ./requirements.txt
RUN pip install install pre-commit pytest==7.4.3 accelerate datasets==2.14.6 peft==0.4.0 scikit-learn -i https://artifacts.antgroup-inc.cn/simple/
RUN pip install --default-timeout=600 dlrover[torch]==0.3.6
ENV NVIDIA_DISABLE_REQUIRE=1
ENV LD_LIBRARY_PATH=/usr/local/cuda/compat/:/usr/local/cuda-12.1/lib64/:/usr/local/nvidia/lib:/usr/local/nvidia/lib64

RUN pip install --default-timeout=600 transformers==4.31.0 -i https://artifacts.antgroup-inc.cn/simple/
RUN mkdir PiPPy && \
    cd PiPPy && \
    wget -O ./pippy.tar.gz https://dlrover.oss-cn-beijing.aliyuncs.com/atorch/libs/pippy_cecc4fc4b015843076b688560c354e14eac2e7c1.tar.gz && \
    tar -xf ./pippy.tar.gz && \
    python setup.py bdist_wheel && \
    pip install dist/torchpippy-0.1.1-py3-none-any.whl && \
    cd .. && \
    rm -rf PiPPy

RUN wget -O ./glpk-5.0.tar.gz https://dlrover.oss-cn-beijing.aliyuncs.com/atorch/libs/glpk-5.0.tar.gz && \
    tar -zxvf glpk-5.0.tar.gz && \
    cd ./glpk-5.0 && \
    ./configure --prefix=/usr && \
    make -j && make install && \
    cd .. && \
    rm -rf glpk-5.0.tar.gz glpk-5.0