# DLRover Brain: A Centralized Management and Optimization System

## Background

While the DLRover Training System provides robust elasticity and fault tolerance for 
individual AI training jobs—ensuring high efficiency and continuity—managing a 
large-scale cluster where multiple tasks run concurrently presents higher-level 
challenges. To address this, we identified two primary requirements: Workload Offloading 
and Training Jobs Management.

### Workload Offloading

While the inherent elasticity is managed at the task level by DLRover, leveraging this 
capability to maximize efficiency requires complex optimization algorithms to determine 
the ideal resource configuration. These algorithms are often computationally intensive. 
Executing them within the training task environment risks resource contention, 
potentially degrading the performance of the model training itself.

### Training Jobs Management

Training tasks across a cluster require diverse and frequently updated configurations. 
These include dynamic adjustments to resource allocation and algorithmic parameters. 
Managing these updates manually or locally for each task lacks the necessary agility for 
large-scale operations.

### Our Solution: DLRover Brain

To meet these requirements, we developed DLRover Brain, an independent service deployed 
separately from the training jobs. By decoupling the optimization logic from the 
execution layer, the system achieves a higher degree of stability and scalability.

Under this architecture, a training job interacts with the Brain service multiple times 
throughout its lifecycle for:

- Performance Optimization: The task retrieves optimized resource plans generated by 
the Brain's sophisticated algorithms.

- Configuration Management: The task fetches the latest parameters to adjust model 
training in real-time.

## Brain Architecture

<div align="center">
<img src="../figures/dlrover_brain_arch.jpg" alt="Async Checkpoint Classes" width="1000">
</div>

Brain is composed of three components: API, Optimization, and Configuration.

### API

The API is responsible for receiving requests from training jobs, dispatching 
them to the relevant components for processing, and finally returning the results to 
the training jobs. Interaction between the training jobs and the Server occurs via 
the HTTP protocol.

### Optimization

The Optimization component is responsible for optimizing training tasks. It consists of 
an optimizer router and multiple optimizers. When processing an optimization request 
for a specific task, the optimizer router selects the appropriate optimizer based on 
the task's characteristics and current status to generate an optimization plan.

For example, an optimization request for a job that has encountered an OOM (Out Of Memory) 
error requires a completely different optimizer compared to a request from a normally 
running job.

### Configuration

This component stores various configurations. When a training task starts, it accesses 
Brain to retrieve its specific configuration. The structure of a configuration is as 
follows:

```yaml
Include:
  User: "user1"
  Group: "group2"
Exclude:
  Cluster: "cluster4"
Configure:
  A: 1
  B: "C"
```

Each configuration consists of three parts. Include and Exclude are used to filter for 
eligible tasks:

- Include: Requires that the job's characteristics match the specified conditions.

- Exclude: Requires that the job does not satisfy the specified conditions.

If a job satisfies both the Include and Exclude criteria, the Configuration is returned 
to be used during the task's training.

These configurations are not stored directly within Brain but on external storage media, 
such as databases (DB) or Kubernetes ConfigMaps. Brain Configuration periodically 
synchronizes with the configurations on these media to ensure that training tasks can 
access the latest settings.
